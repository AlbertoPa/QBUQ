%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  Documentation of the QBUQ package for MFIX                %
%                                                            %          
%  Author: Xiaofei Hu <xhu@iastate.edu>                      %
%  Reviewer: Alberto Passalacqua <albertop@iastate.edu>      %
%            Rodney O. Fox <rofox@iastate.edu>               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a4paper,12pt,titlepage]{article}

\usepackage{amsmath,amssymb}

\usepackage{parskip}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}
\usepackage{paralist}
\usepackage{enumitem}

\newcommand{\xbf}{\mathbf{x}}
\newcommand{\xibf}{\boldsymbol{\xi}}
\newcommand{\Psibf}{\boldsymbol{\Psi}}
\newcommand{\samplespace}{\Omega}
\newcommand{\probspace}{\mathcal{P}}
\newcommand{\sigmaalgebra}{\mathfrak{F}}

\newcommand{\drm}{\textrm{d}}
\newcommand{\Mrm}{\textrm{M}}
\newcommand{\Nrm}{\textrm{N}}
\newcommand{\Qrm}{\textrm{Q}}
\newcommand{\MFIX}{MFiX }

\begin{document}

\begin{titlepage}
\title{An Example application of the Quadrature-Based Uncertainty Quantification
Package for \MFIX}

\author{Xiaofei Hu \\ 
        xhu@iastate.edu \\
        Department of Chemical and Biological Engineering \\
        Iowa State University \\
        Ames, IA, USA \\
        \and
        Alberto Passalacqua \\
        albertop@iastate.edu \\
        Department of Mechanical  Engineering \\
        Iowa State University \\
        Ames, IA, USA \\
        \and
        Rodney O. Fox \\
        rofox@iastate.edu \\
        Department of Chemical and Biological Engineering \\
        Iowa State University \\
        Ames, IA, USA}
\date{December 3rd, 2013}
\maketitle
\end{titlepage}

\section{Introduction}
\label{sec:Introduction}
This document provides an example of using the non-intrusive quadrature-based
uncertainty quantification (QBUQ) package implemented in \MFIX. The package is
made of two parts: pre-processing and post-processing modules. In the
pre-processing module, the space of the uncertain input parameters is sampled
first, quadrature weights and nodes are obtained, and the corresponding \MFIX
input file mfix.dat for each sample is generated. A set of \MFIX simulations can
be performed to obtain quadrature abscissas. In the post-processing module,
moments of the system response are estimated. Low order statistics, including
mean, variance, skewness, and kurtosis are calculated, and the probability
distribution function (PDF) of the system response at specific locations
specified by the user can be reconstructed. In the following parts, the \MFIX
tutorial case fluidBed1, with uncertain particle, size is used as an example
case to illustrate the QBUQ procedure.

\section{An example to run QBUQ package}
\label{sec:ExampleQBUQ}
The QBUQ modules are written in python 3. The example shown here is using
python 3 (version 3.2.3) \cite{Python} with the following packages:
\begin{itemize}
 \item NumPy -- Version 1.7.1 \cite{NumPy}
 \item SciPy -- Version 0.12.0 \cite{SciPy}
 \item SymPy -- Version 0.7.2 \cite{SymPy}
\end{itemize}
Simulations are run using \MFIX-2013-1, and bash shell is used for shell scripts.

\emph{\underline{Notes:}} 
\begin{itemize}
 \item We assume python3 is the command running python 3, since many systems still default to python 2.x. If your operating systems uses python 3 by default, replace each instance of the ``python3'' command with ``python''.
 \item The QBUQ package was tested on Linux systems based on openSUSE 12.3 and openSUSE 13.1 \cite{openSUSE}.
\end{itemize}

The \MFIX tutorial case fluidBed1 is used as an example case in this section. It
is a 2-D bubbling fluidized bed reactor with a central jet. The uncertain
parameter in this example is the particle diameter, uniformly distributed from
$300\ \mu\textrm{m}$ to $500\ \mu\textrm{m}$. In order to use the QBUQ package,
create a new run directory, and put the following directory and files in your
run directory:\ directory ``qbuq\_package'', python 3 files ``pre\_qbuq.py'' and
``post\_qbuq.py'', and bash script files ``run\_serial'' and ``extract\_data''.
You also need to provide a basic mfix.dat file in the run directory to use for
generating mfix.dat file for each sample.

\subsection{Pre-processing module}
\label{sec:Pre-processing}
The pre-processing module samples the space of uncertain parameters (particle
diameter in the example case), generates quadrature weights and nodes, and
creates the corresponding \MFIX input files. The python 3 file ``pre\_qbuq.py''
is the main script, and the corresponding functions are in the sub-package
``pre\_processing'' under the package ``qbuq\_package''. To use the module,
follow the following procedure.

\begin{enumerate}[leftmargin=0cm,itemindent=0.5cm]
 \item Go to your \emph{run directory} in a terminal, then type the command 
  below to run the module:
  
  \textbf{python3 pre\_qbuq.py}
  
 \item Type \textbf{1} to select ``1 -- Univariate problem''.
 
 The program asks you to choose the number of uncertain parameters. Only
 univariate and bivariate problems are available at the moment. For our case,
 the only uncertain parameter is the particle diameter.
 
 \item Type \textbf{y} for known distribution.
 
 The program asks if the distribution of the variable is known. Since the 
 particle diameter in our example is uniformly distributed, we choose ``yes''.
 
 \item Type \textbf{1} to choose ``Uniform distribution''.
 
 \item Type \textbf{10} to generate ten samples in the example.
 
 \item Enter \textbf{0.03} as the minimum value and \textbf{0.05} as the maximum
 value.
 
 This is the range of your uniformly distributed uncertain parameter. Remember, 
 in the basic \MFIX input file mfix.dat, the units system we use is 
 ``\emph{cgs}''. Therefore, our range of particle diameter is 
 $0.03\ \textrm{cm}$ to $0.05\ \textrm{cm}$.
\end{enumerate}

So far the first step (sample the space of uncertain parameter) is completed.
The program says a text file containing quadrature weights and nodes is
generated successfully. The name of this file is
``quadrature\_weights\_nodes.txt'', in which the first row shows quadrature
weights, and the second row shows quadrature nodes. Then the program starts to
generate the \MFIX input files for each sample.

\begin{enumerate}[resume,leftmargin=0cm,itemindent=0.5cm]
 \item Type \textbf{Test} as the head of the run\_name.
 
 The head of the run\_name is case sensitive. The run\_name for each mfix.dat 
 file will be this head followed by a number. In our case, with increasing 
 particle size, the run\_name will be Test0 to Test9.
 
 \item Enter \textbf{1} as the number of keywords in mfix.dat file use the value
 of the uncertain parameter.
 
 Please count carefully to include all the keywords related to the uncertain 
 parameter. In our case, only one keyword ``\emph{D\_p0}'' is related to 
 particle diameter.
 
 \item Type \textbf{D\_p0} as the name of the keyword.
 
 \emph{\underline{Note:}} The keywords typed here should be exactly the same 
 as those in the basic mfix.dat file because these keywords will be searched 
 and their values will be replaced by the quadrature nodes. If the keywords 
 do not match, the values will not be replaced.
 
The program then searches the keywords ``\emph{run\_name}'' and ``\emph{D\_p0}''
in the basic mfix.dat file, and replaces their values with the new run\_name and
quadrature node value, respectively. The \MFIX input file mfix.dat generated for
each sample is stored in separate directories named by their run\_name. A text
file named ``\emph{list\_of\_cases.txt}'' is also generated, which contains
run\_name of each sample in the order of increasing quadrature nodes so that in
post-processing part quadrature weights and nodes match. \end{enumerate}

The pre-processing part of QBUQ procedure is now completed. The program says the
\MFIX input files are generated successfully. In the run directory, you should
have two more text files, ``quadrature\_weights\_nodes.txt'' and
``list\_of\_cases.txt'', and ten more folders named from Test0 to Test9, each
one containing a \MFIX input file mfix.dat. The only difference among these input
files is the value of \emph{D\_p0}. In the next section, we will see how to use
the shell script ``run\_serial'' to run the simulations in serial.

\subsection{Running simulations in serial}
\label{sec:RunSerial}
A bash script ``run\_serial'' is written to run generated \MFIX simulations in
serial. In this example, when we compile \MFIX, the serial mode of execution for
each sample is selected. To run \MFIX in DMP or SMP mode, please change the
commands in this file accordingly. If you want to submit your jobs on a cluster
through a batch queue system, please consult with your system administrator.

To use the script ``run\_serial'', in the run directory, type:

\textbf{bash run\_serial MFIX\_model\_directory}

Here the ``MFIX\_model\_directory'' is the path of your \MFIX model directory,
such as ``/home/mfix/model''.

The program prompts the initial compilation of MFIX. The options used in this
initial compilation will be used for all the simulations generated
in~\ref{sec:Pre-processing}. The options used in this example are following:

\begin{itemize}
 \item Mode of execution: [1] Serial
 \item Level of optimization: [3] Level 3 (most aggressive)
 \item Option to re-compile source files in run directory: 
 
 [1] Do not force re-compilation
 \item Compiler selection: [1] GNU (gfortran) version 4.3 and above
\end{itemize}

After the initial compilation, the same options are used repeatedly for all the
simulations. From Test0 to Test9, simulations are compiled and run in the order
listed in text file ``list\_of\_cases.txt''. The screen outputs of compilation
and run for each simulation are redirected to log files ``compile.log'' and
``run.log'', respectively. Once all the simulations are completed, time-averaged
quantities can be extracted, and the post-processing module of QBUQ can be used.

\subsection{Post-processing module}
\label{sec:Post-processing}

The post-processing module first extracts time-averaged quantities with a bash
shell script ``extract\_data'' by calling \MFIX post-processing program
``post\_mfix''. Time-averaged results can then be used with the QBUQ
post-\\processing module ``post\_qbuq.py''. The module can perform two tasks:\
estimate moments and low order statistics (mean, variance, skewness, and
kurtosis), and reconstruct the PDF of system response. The functions used in
this module are in the sub-package ``post\_processing'' under the package
``qbuq\_package''.

\subsubsection{Extracting time-averaged data}
\label{sec:ExtractData}

To extract time-averaged quantities, a basic text file needs to be provided in
the run directory to use as the input file for \MFIX post-processing program
``post\_mfix''. Then the bash shell script ``extract\_data'' will replace the
run\_name automatically and extract the data for each simulation. In this
example, two basic text files are provided in the run directory:\
``post\_all.txt'' extracts time-averaged quantities on the whole computational
domain which will be used for estimation of moments and low order statistics,
and \\``post\_point.txt'' extracts data at one specific location which will be
used for reconstruction of the PDF. The following sections show what settings
are used in these two post\_mfix input files for \MFIX post-processing program.

\emph{\underline{Note:}} When chosing the file name where the extracted data are
stored, a .txt file extension must be added. Only .txt files can be read by the
post\_qbuq module.

\paragraph*{post\_all.txt}

\begin{itemize}
 \item RUN\_NAME to post\_procss $>$ Test (\emph{\underline{Note:}} This name 
 will be replaced automatically with the run\_name of each simulation.)
 \item Enter menu selection $>$ 1 - Examine/print data
 \item Write output using user-supplied precision? (T/F) $>$ f
 \item Time:(0.000, 0.000) $>$ 0, 2
 \item Time average? (N) $>$ y
 \item Variable:\ (EP\_g) $>$ EP\_g
 \item I range:\ (1, 1) $>$ 1, 9
 \item Average or sum over I? (N) $>$ n
 \item J range:\ (1, 1) $>$ 1, 102
 \item Average or sum over J? (N)  $>$ n
 \item K range:\ (1, 1) $>$ 1, 1
 \item File:\ (*) $>$ EP\_g\_all.txt (\emph{\underline{Note:}} Must use .txt 
 file here. The post\_qbuq module only reads .txt files.)
 \item Time:(0.000, 0.000) $>$ -1
 \item Enter menu selection $>$ 0 - Exit POST\_MFIX
\end{itemize}

Only the gas volume fraction ``\emph{EP\_g}'' is extracted for the whole
computational domain as an example. Other time-averaged quantities can be
extracted by changing or adding conditions in the file accordingly.

\paragraph*{post\_point.txt}

\begin{itemize}
 \item RUN\_NAME to post\_procss $>$ Test
 \item Enter menu selection $>$ 1 - Examine/print data
 \item Write output using user-supplied precision? (T/F) $>$ f
 \item Time:(0.000, 0.000) $>$ 0, 2
 \item Time average? (N) $>$ y
 \item Variable:\ (EP\_g) $>$ EP\_g
 \item I range:\ (1, 1) $>$ 7, 7
 \item J range:\ (1, 1) $>$ 51, 51
 \item K range:\ (1, 1) $>$ 1, 1
 \item File:\ (*) $>$ EP\_g.txt (\emph{\underline{Note:}} Must use .txt 
 file here. The post\_qbuq module only reads .txt files.)
 \item Time:(0.000, 0.000) $>$ 0, 2
 \item Time average? (N) $>$ y
 \item Variable:\ (EP\_g) $>$ P\_g
 \item I range:\ (1, 1) $>$ 7, 7
 \item J range:\ (1, 1) $>$ 51, 51
 \item K range:\ (1, 1) $>$ 1, 1
 \item File:\ (*) $>$ P\_g.txt
 \item Time:(0.000, 0.000) $>$ 0, 2
 \item Time average? (N) $>$ y
 \item Variable:\ (EP\_g) $>$ V\_s
 \item I range:\ (1, 1) $>$ 7, 7
 \item J range:\ (1, 1) $>$ 51, 51
 \item K range:\ (1, 1) $>$ 1, 1
 \item File:\ (*) $>$ V\_s.txt 
 \item Time:(0.000, 0.000) $>$ -1
 \item Enter menu selection $>$ 0 - Exit POST\_MFIX
\end{itemize}

Gas volume fraction ``\emph{EP\_g}'', gas pressure ``\emph{P\_g}'' and vertical
solid velocity ``\emph{V\_s}'' are extracted at a specific location. Conditions
in the file can be changed or added accordingly.

To use the bash shell script ``extract\_data'' to extract time-averaged data for
all the simulations in the run directory, type:

\textbf{bash extract\_data post\_file post\_mfix\_directory}

Here the ``post\_file'' is the file used as input for the \MFIX post-processing
program ``post\_mfix''. In this example, it can be either ``post\_all.txt'' or
``post\_point.txt''. The ``post\_mfix\_directory'' is the path of your \MFIX\\
post\_mfix directory, such as ``/home/mfix/post\_mfix''. We run the script twice
using both ``post\_all.txt'' and ``post\_point.txt'' to extract gas volume
fraction ``\emph{EP\_g}'' on the whole computational domain, and gas volume
fraction ``\emph{EP\_g}'', gas pressure ``\emph{P\_g}'' and vertical solid
velocity ``\emph{V\_s}'' at a specific location for all ten simulations. Once
the process is completed, these data can be used with the post\_qbuq module.

\subsubsection{Estimation of moments and low order statistics}
\label{sec:LowOrder}

Two tasks can be performed by the QBUQ post-processing module, estimation of
moments and low order statistics, and reconstruction of the PDF of the system
response. We first show how to estimate the moments and low order statistics of
the PDF of the system response.

\begin{enumerate}[leftmargin=0cm,itemindent=0.5cm]
 \item In the run directory, type the following command to run the module:
 
  \textbf{python3 post\_qbuq.py}
  
 \item Type \textbf{1} to choose ``1 -- Calculate low order statistics''.
 
 \item Type \textbf{EP\_g\_all.txt} to continue.
 
 Here the program asks for the file name of the quantity of interest. In this
 example, it is the file name used in file ``post\_all.txt'',
 ``EP\_g\_all.txt''.
 
 \item Type \textbf{10} for ten samples in this example.
 
 \item Type \textbf{4} as the highest order of moments.
 
 In order to estimate low order statistics including mean, variance, skewness, 
 and kurtosis, at least the fourth-order moment is needed.
\end{enumerate}

The program uses the time-averaged data of each simulation extracted
in~\ref{sec:ExtractData} as quadrature abscissas and quadrature weights
generated in~\ref{sec:Pre-processing} to estimate moments of the gas volume
fraction ``\emph{EP\_g}'' up to the fourth order, on the whole computational
domain. Mean, variance, skewness, and kurtosis are calculated as well. A runtime
warning may be displayed at this point because, when calculating skewness and
kurtosis, the standard deviation as the denominator may become 0 at some
location. These warnings do not affect the results at other locations.

Once the program has run, five more text files are generated in the run
directory:\ ``moments.txt'', ``mean.txt'', ``variance.txt'', ``skewness.txt'',
and ``kurtosis.txt''.

\emph{\underline{Note:}} Make sure these files are stored and renamed correctly
before using the post\_qbuq module again. These files will be overwritten when
the module is used for other quantities of interest.

\subsubsection{Reconstruction of the PDF}
\label{sec:Reconstruction}

We now illustrate an example of reconstructing the PDF of the system response.
The PDF of three quantities, gas volume fraction ``\emph{EP\_g}'', gas pressure
``\emph{P\_g}'' and vertical solid velocity ``\emph{V\_s}'', at a specific
location are reconstructed using extended quadrature method of moments
(EQMOM)\cite{Chalons2010,YuanLaurentFox2011}.

\paragraph{Gas volume fraction ``\emph{EP\_g}''}\mbox{}\\
\label{sec:ReconEPg}

\begin{enumerate}[leftmargin=0cm,itemindent=0.5cm]
 \item Type the following command in the run directory to run the QBUQ 
 post-processing module:
 
 \textbf{python3 post\_qbuq.py}
 
 \item Type \textbf{2} to select ``2 -- Reconstruction the probability 
 distribution function''.
 
 \item Enter \textbf{1} to choose $\beta$-EQMOM for \emph{EP\_g}.
 
 \item Type \textbf{4} as number of nodes.
 
 Maximum 5 nodes can be used in $\beta$-EQMOM and $\gamma$-EQMOM.
 
 \item Type \textbf{0}, $\mathbf{1e-12}$, $\mathbf{1e-8}$, and $\mathbf{1e-4}$
 as $rmin(0)$, $rmin(1)$, $rmin(2)$, and $rmin(3)$, respectively.
 
 These are the four ratios of minimum to maximum weight (rmin), which are
 parameters used in adaptive Wheeler algorithm~\cite{YuanFox2011}.
 
 \item Enter $\mathbf{1e-10}$ as eabs.
 
 This is the minimum distance between distinct nodes, which is also a parameter
 used in the adaptive Wheeler algorithm~\cite{YuanFox2011}.
 
 \item Type \textbf{10} for a total of ten simulations in this example.
 
 \item Type \textbf{EP\_g.txt} as the file name of quantity of interest.
 
 \item Enter \textbf{1} to use minimum to maximum value of the data as the 
 interval.
 
 In $\beta$-EQMOM, a bounded interval is needed. In the post\_qbuq module, the
 bounded interval can either use the minimum to maximum value of the data or be
 set up manually.
\end{enumerate}

The program then uses $\beta$-EQMOM to reconstruct the PDF of the gas volume
fraction. Once this is completed, $\sigma$, weights, nodes on $[0,1]$, and nodes
on bounded interval are shown on the screen. Three more text files are generated
in the run directory. The ``betaEQMOM\_sigma.txt'' file keeps the value of
$\sigma$. In the ``betaEQMOM\_weights\_nodes.txt'' file, the first row shows the
weights of each EQMOM node, the second row gives the value of each EQMOM node on
$[0,1]$, and the third row shows the value of each EQMOM node on the bounded
interval. The ``data\_set\_for\_betaEQMOM.txt'' file contains ten values used to
reconstruct the gas volume fraction, each of which is the value of gas volume
fraction of that simulation at the specific location.

For your reference, Table~\ref{tab:ReconEPg} gives the results shown on the
screen for the example case.

\begin{table}[htp]
 \centering
 \begin{tabular}{l|ll} \hline
  sigma       & \multicolumn{2}{l}{0.00523497997459} \\ \hline
  weights     & 0.46426887803    & 0.284369847782    \\ 
              & 0.217899463915   & 0.033461810273    \\ \hline
  nodes       & 0.00956478087672 & 0.0894838372351   \\
  on $[0, 1]$ & 0.629186940922   & 0.999750406862    \\ \hline
  nodes       & 0.415734483248   & 0.425965720843    \\ 
  on $[a, b]$ & 0.495058512177   & 0.542498047086    \\ \hline
 \end{tabular}
 \caption{Reconstruction results for the gas volume fraction using $\beta$-EQMOM.}
 \label{tab:ReconEPg}
\end{table}

\paragraph{Gas pressure ``\emph{P\_g}''}\mbox{}\\
\label{sec:ReconPg}

The procedure of using post\_qbuq module to reconstruct the PDF of gas pressure
\emph{P\_g} at the location is similar to the one used in~\ref{sec:ReconEPg}
except that different options are selected. Conditions used in the module to
reconstruct the PDF of gas pressure are as follows.

\begin{itemize}
 \item Type \textbf{python3 post\_qbuq.py} to run the module.
 \item Type \textbf{2} to select reconstruction of the PDF.
 \item Type \textbf{2} to use $\gamma$-EQMOM to reconstruct the PDF of gas 
 pressure.
 \item Enter \textbf{5} as the number of EQMOM nodes.
 \item For the parameters rmin in adaptive Wheeler algorithm, the first four are 
 the same with~\ref{sec:ReconEPg}. Type $\mathbf{1e-4}$ for the fifth one 
 $rmin[4]$.
 \item Use $\mathbf{1e-10}$ again as eabs in adaptive Wheeler algorithm.
 \item Enter \textbf{10} for 10 samples.
 \item The file name of gas pressure in this example is \textbf{P\_g.txt}.
 \item Select \textbf{2} to set the lower bound for $\gamma$-EQMOM manually.
 \item Type \textbf{200} as the lower bound.
\end{itemize}

Once the reconstruction is completed, three more files are generated in the run
directory:\ ``gammaEQMOM\_sigma.txt'', ``gammaEQMOM\_weights\_nodes.txt'', and
``data\_set\_for\_gammaEQMOM.txt''. Table~\ref{tab:ReconPg} gives results shown
on screen for your reference.

\begin{table}[htp]
 \centering
 \begin{tabular}{l|lll} \hline
  sigma            & \multicolumn{3}{l}{19.606992775}                 \\ \hline
  weights          & 0.177257589525 & 0.27693370017  & 0.181902294417 \\ 
                   & 0.150325247342 & 0.213581168547 &                \\ \hline
  nodes            & 283.874714748  & 1536.18411219  & 3175.10056231  \\
  on $[0, \infty)$ & 4271.74179277  & 6774.60334977  &                \\ \hline
  nodes            & 483.874714748  & 1736.18411219  & 3375.10056231  \\ 
  on $[a, \infty)$ & 4471.74179277  & 6974.60334977  &                \\ \hline
 \end{tabular}
 \caption{Reconstruction results of gas pressure using $\gamma$-EQMOM.}
 \label{tab:ReconPg}
\end{table}

\paragraph{Vertical solid velocity ``\emph{V\_s}''}\mbox{}\\
\label{sec:ReconVs}

The procedure of using post\_qbuq module to reconstruct the PDF of vertical
solid velocity \emph{V\_s} at the location is slightly different from the
procedure used in~\ref{sec:ReconEPg} and~\ref{sec:ReconPg}, since $2$-node
Gaussian EQMOM is used\cite{Chalons2010}. The procedure is as follows.

\begin{itemize}
 \item Type \textbf{python3 post\_qbuq.py} to run the module.
 \item Type \textbf{2} to select reconstruction of the PDF.
 \item Type \textbf{3} to use $2$-node Gaussian EQMOM to reconstruct the PDF of 
 vertical solid velocity.
 \item Enter \textbf{10} for 10 samples.
 \item The file name of vertical solid velocity in this example is 
 \textbf{V\_s.txt}.
\end{itemize}

Three more files are generated in the run directory once the reconstruction is
completed:\ ``GaussianEQMOM\_sigma.txt'',
\\``GaussianEQMOM\_weights\_nodes.txt'', and
\\``data\_set\_for\_GaussianEQMOM.txt''. Table~\ref{tab:ReconVs} gives results
on author's screen for your reference.

\begin{table}[htp]
 \centering
 \begin{tabular}{l|ll} \hline
  sigma   & \multicolumn{2}{l}{1.93623130711} \\ \hline
  weights & 0.694653795117 & 0.305346204883   \\ \hline
  nodes   & -5.1032997211  & 3.10647288573    \\ \hline
 \end{tabular}
 \caption{Reconstruction results of vertical solid velocity using $2$-node 
 Gaussian EQMOM.}
 \label{tab:ReconVs}
\end{table}

\bibliographystyle{plain}
\bibliography{qbuq_example}

\end{document}

% End of document
